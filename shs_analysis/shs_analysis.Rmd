---
title: "Kenya Soil Health Study Analysis"
author: '[Matt Lowes](mailto:matt.lowes@oneacrefund.org)'
date: '`r format(Sys.time(), "%B %d, %Y")`'
output:
  html_notebook:
    number_sections: yes
    code_folding: show
    theme: flatly
    toc: yes
    toc_depth: 6
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message=F}
rm(list = ls())
cat("\014")

## set up some global options
# always set stringsAsFactors = F when loading data
options(stringsAsFactors=FALSE)

# show the code
knitr::opts_chunk$set(echo = TRUE)

# define all knitr tables to be html format
options(knitr.table.format = 'html')

# change code chunk default to not show warnings or messages
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

libs <- c("tidyverse", "knitr", "readxl", 
    "MASS", "gridExtra", "robustbase",
    "sp", "dismo", "leaflet", "XML", "ggmap", "kableExtra",
    "NbClust", "clValid", "ggfortify", "clustree", "dendextend", "FactoMineR", "corrplot", "GGally")
lapply(libs, require, character.only = T, quietly = T, warn.conflicts = F)

#### define helpful functions
# define function to adjust table widths
html_table_width <- function(kable_output, width) {
  width_html <- paste0(paste0('<col width="', width, '">'), collapse = "\n")
  sub("<table>", paste0("<table>\n", width_html), kable_output)
}

source("../../oaflib/commcareExport.R")
source("../../oaflib/misc.R")
source("../../oaflib/plm.R")
select <- dplyr::select

forceUpdateAll <- FALSE
```

# Background

This file will pick up on from the Kenya round 1 file and finish the analysis. The cleaning of the data up through the round 1 data (baseline and round 1) happens in the `kenya_round_1` folder. Going forward, the cleaning of new data will happen in the `shs_cleaning.R` file, which I'll source here, and then the analysis will happen here.

# Objective

Analyze the soil health study data.

# Data
```{r}
# load the latest kenya data from the cleaning file >> or maybe do the combining there.
#source("shs_cleaning.R")

keDat <- readRDS("ke_cleaned_combined_fieldDat.rds")
rwDat <- readRDS("rw_cleaned_combined_fieldDat.rds")


```

# Analysis

## Check identifiers

**It's hard to know where to draw the line between cleaning and analysis. I'm going to keep this code here even though it's technically additional data cleaning**


Check that we're actually dealing with clients for which we have multiple records
```{r}
table(table(rwDat$sample_id)==5) 
```

So we have some clients for which we don't have 3 records, one for each survey. Find out what the deal is.

```{r}
table(table(rwDat$sample_id))
```

Hm. So the numbers less than 5 could be that we're just not finding people every year. But the 1s and 2s are particularly strange. Let's check those out. Here's a [helpful link](https://stackoverflow.com/questions/41875078/how-to-identify-indexes-of-elements-appearing-only-once-in-a-vector-in-r)

```{r}
singleSurvey <- names(which(table(rwDat$sample_id) == 1))

rwDat %>%
  filter(sample_id == singleSurvey)
                     
                     
```

Looks like this person was only surveyed in the first season. Okay. Check out the other seasons

```{r}
twoSurveys <- names(which(table(rwDat$sample_id) == 2))
rwDat %>%
  filter(sample_id %in% twoSurveys)
```

Okay, these are from the recent round but they don't have any previous surveys which is odd. We shouldn't be adding new farmers into the survey.  These can be dropped for simplicity. I can follow up with Eric and Cyprien to find out the issue but I'm just going to drop them for now.

```{r}
rwDat <- rwDat %>%
  filter(!sample_id %in% twoSurveys)
```

```{r}
fourSurveys <- names(which(table(rwDat$sample_id)==4))
rwDat %>%
  filter(sample_id %in% fourSurveys)
```

Okay. There are enough surveys in the 3 and 4 category that they're at least plausible from a data quality and survey strategy perspective. I'll leave them as they are.

## Surveys for which we don't have soil

Check that there isn't something systematic in these surveys. If so, describe what it is.

### Attrition analysis for appendix

Create a record of how many farmers are joining and leaving Tubura between the baseline through the current survey round. These numbers only reflect the changes from the last round.

**This also should account for clients that we miss in each season so we can say what the attrition has been season to season. Also, why don't we have 16A results for Rwanda. Find out what's happening there.**

```{r}
clientCount <- function(dat){
  # this assumes season, d_client, and sample_id remain the names of 
  # the key variables. They should for the data to match.
  
  # this funciton tablulates the number of clients in each season
  iniTab <- dat %>%
    filter(!is.na(d_client)) %>%
    group_by(season, d_client) %>%
    tally() %>%
    gather(key, value, -c(season, d_client)) %>%
    spread(d_client, value) %>%
    rename(control = `0`,
         client = `1`) %>%
    mutate(control = as.numeric(control),
         client = as.numeric(client)) %>%
    rowwise() %>%
    mutate(total = sum(control, client)) %>%
    ungroup()
    
  percentDiff <- iniTab %>%
    mutate(pct_change = (((total - lead(total))/total) * 100))
  return(percentDiff)    
  
}

rw.attrition.tab <- clientCount(rwDat)

ke.attrition.tab <- clientCount(keDat)

```

```{r}
attritionRate <- function(org, new){
  return((org - new)/org * 100)
}


attritionRate(2028, 1935)  # kenya
attritionRate(2439, 2409) # rwanda
attritionRate(4467, 4344) # total
```


## Soil graphs

```{r}
ggplot(rwDat, aes(x = season, y = ph, group = d_client)) + geom_boxplot()
```

### Variable check

```{r}
ggplot(keDat, aes(x = can.acre)) + 
  geom_histogram() +
  scale_x_continuous(limits = c(0,200)) +
  labs(title = "Set limits to 0 and 100 for CAN")

ggplot(keDat, aes(x = dap.acre)) + 
  geom_histogram() +
  scale_x_continuous(limits = c(0,200)) +
  labs(title = "Set limits to 0 and 100 for DAP")


```


Check values for upcoming final round of Kenya SHS data collection

This is ideally a grouped boxplot. Fix this when I have internet. This would show the values by season and client type.

### Regressions

See [sketch of SHS report](https://docs.google.com/document/d/1koNsKzx97_3rpkGeJI6PnPdYNMdV9q4e-cPQxAWDeDk/edit).  Remember that `sameStatus` are the farmers that kept their status between baseline and endline. The two models of interest are:

* Individual fixed effects account for things specific to farmer that don't change over time
* can control for unobserved sources of heterogeneity over time, very sensitive to model 
* add in other data points that do change over time
* so add in things that change over time that plausibly affect our outcome
* fertilizer and seed use are synonymous with being a client or not, highly endogenous
* run two regs
 + one with oaf 
 + one with oaf and fertilizer
* things like slope are collinear
* individual fixed effects makes more sense than using PSM now that we have multiple years.
* means by directional changes
* papers using fixed effects by Miguel on whether changes to rural to urban areas and income

[Helpful link](https://www.r-bloggers.com/how-to-go-parallel-in-r-basics-tips/) for executing code in parallel

# Nitrogen effect

Before running the full models, I'm going to take a closer look at the nitrogen data to make sure we can explain the negative effects we're seeing in Kenya in the models below. There isn't a clear agronomic explanation for the negative effect and as a consequence we're put in a bind in our reporting to explain either the outcome or the modeling.

Let's start with looking at the relationship between nitrogen and other features to make sure we're seeing what expect:

### Nitrogen alone

The big takeaway for me from this plot is that there are regular spikes at certain values. That seems odd for a system that should be pretty continuous. Let's see if that plays out evenly across seasons.

```{r}
keDat %>%
  ggplot(., aes(x = total.nitrogen)) + 
  geom_histogram(bins = 100) +
  geom_density()
```

```{r}
keDat %>%
  ggplot(., aes(x = total.nitrogen)) + 
  geom_histogram() +
  geom_vline(xintercept = mean(keDat$total.nitrogen, na.rm = T)) +
  facet_grid(~ season)

# ggplot() +
#   geom_histogram(data = filter(keDat, keDat$season == 2015), aes(x = total.nitrogen, fill = 'red'), alpha = 0.5) +
#   geom_histogram(data = filter(keDat, keDat$season == 2016), aes(x = total.nitrogen, fill = 'blue'), alpha = 0.5) +
#   geom_histogram(data = filter(keDat, keDat$season == 2017), aes(x = total.nitrogen, fill = 'green'), alpha = 0.5) +
#   theme(legend.position = 'none')
```
### Nitrogen by season

This is what we're observing. There's a clear downward trend across seasons with perhaps a slight shift downward for 

```{r}
keDat %>%
  #select(season, total.nitrogen, d_client) %>%
  ggplot(., aes(x = season, y = total.nitrogen, fill = as.factor(d_client))) + 
  geom_boxplot() + 
  theme(legend.position = 'bottom') +
  labs(title = "Total N by season and client status", subtitle ="Strong seasonal trend with perhaps a slight client trend downward",
       x = "Season", y = "Total N", fill = "Client Status")
```

```{r}
keDat %>%
  filter(!is.na(d_client)) %>%
  group_by(season, d_client) %>% 
  summarize(mean = round(mean(total.nitrogen, na.rm = T),4)) %>%
  kable(caption = "Downward average N by season") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```

1AF clients are slightly below comparison farmers in terms of total nitrogren but the difference is ever so slight. Perhaps in the context of soil chemistry these are big differencs though!

### Nitrogen and carbon

```{r}
keDat %>%
  ggplot(., aes(x = organic.carbon, y = total.nitrogen)) + 
  geom_point() +
  labs(title = "N vs. C - what we'd expect", x = "Total N", y = "Organic C")
```

```{r}
keDat %>%
  ggplot(., aes(x = organic.carbon, y = total.nitrogen)) + 
  geom_point() +
  labs(title = "N vs. C by season - again what we'd expect", x = "Total N", y = "Organic C") +
  facet_grid(~ season)
```

This is the same table as above but shows carbon level by season and client status. We don't see the same gap widening between client and non-client plots that we see with nitrogen.

```{r}
keDat %>%
  filter(!is.na(d_client)) %>%
  group_by(season, d_client) %>% 
  summarize(mean = round(mean(organic.carbon, na.rm = T),4)) %>%
  kable(caption = "Carbon levels trend together by client status over seasons") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```

### Nitrogen and compost

**if you applied compost since there are so many 0s and removing super large values**

```{r}
keDat %>%
  filter(compost.acre > 0 & compost.acre < 1000) %>%
  ggplot(., aes(x = compost.acre, y = total.nitrogen)) +
  geom_point() +
  facet_grid(~ season) +
  labs(title = "N vs. compost", subtitle = "Relationship less clear")
```

```{r}
# dap 18% n, can 26%
keDat %>%
  mutate(can_n = can.acre * 0.26,
         dap_n = dap.acre * 0.18) %>%
  rowwise() %>%
  mutate(total_n_applied = sum(can_n, dap_n, na.rm = T)) %>%
  filter(total_n_applied > 0) %>%
  ggplot(., aes(x = total_n_applied, y = total.nitrogen)) +
  geom_point() +
  facet_grid(~ season)
```

**Interpretation**: There doesn't seem to be a strong relationship between total N applied and total nitrogen in the soil. It's not clear to me what we should have expected from this relationship but in general I don't see anything odd.

## What moves with nitrogen?

Consider using PCA to simplify the data into components that move in the same direction or opposite of nitrogen to understand the main relationships in the data.



```{r}
keySoilVars <- c("ph", "calcium", "total.nitrogen", "organic.carbon", "magnesium")
```

#### Kenya models

```{r}
keDat <- keDat %>% mutate(age2 = age^2)


indFeList <- list("as.factor(d_client)", 
                  c("as.factor(d_client)", "as.factor(sample_id)"),
                  c("as.factor(d_client)", "as.factor(sample_id)", "as.factor(season)"),
                  c("as.factor(d_client)", "as.factor(sample_id)", "as.factor(season)", "age", "age2"))


# run this in parallel to speed up the process
# load the data and variables and packages into the cluster
regFileKe <- "regFile_through2017.RData"
forceUpdate <- forceUpdateAll

if(!file.exists(regFileKe) || forceUpdate) {
library(parallel)
no_cores <- detectCores() - 1

cl <- makeCluster(no_cores, type="FORK")
clusterEvalQ(cl, "plm")
clusterExport(cl, "keDat")
clusterExport(cl, "keySoilVars")
clusterExport(cl, "indFeList")

indFeLoopKe <- parLapply(cl, indFeList, function(mod){
  lapply(keySoilVars, function(outcome){
    form = lm(reformulate(termlabels = mod, response = outcome), data=keDat)
    
    pdf(file=paste("output/ke2017/", paste0(outcome, paste(mod, collapse = "")), ".pdf", sep = "")) 
    print(plot(form))
    dev.off()
    
    form = plm(form, c("sample_id", "age", "age2"))
    
    rownames(form) = paste(rownames(form), outcome, sep = " ")
    return(form)
  })
  
})
stopCluster(cl)
save(indFeLoopKe, file=regFileKe)
} else {
  load(regFileKe)
}
```

And combine model outputs into tables for each model

```{r}
modExportKe <- lapply(indFeLoopKe, function(models){
  do.call(rbind, models)
})


for(i in 1:length(modExportKe)){
  write.csv(modExportKe[i], file=paste0("output/ke2017/","regOutput_", i, ".csv"), row.names = T)
}

```

In the individual fixed effect model above, the naive model would only include a client indicator and individual fixed effects. If we add season, we lose significance on almost everything. I'd guess that as we add more likely controls we additionally lose significance. I've included age and age squared along the lines of [Hicks et.al](http://www.nber.org/papers/w23253).


```{r}
finalModelKe <- modExportKe[4]

kable(finalModelKe, format="markdown")
write.csv(finalModelKe, file="output/ke2017/indFe_ke2017.csv")
```


#### Rwanda models

The parallel model wasn't running for some reason so I'm just going to run the one model I really want to look at and save those results.


```{r}
rwDat <- rwDat %>% mutate(age2 = age^2)

rwDat <- do.call(data.frame,lapply(rwDat, function(x){ 
  replace(x, is.infinite(x),NA)
  }))

```

```{r, eval=F}
indFeList <- list("as.factor(d_client)", 
                  c("as.factor(d_client)", "as.factor(sample_id)"),
                  c("as.factor(d_client)", "as.factor(sample_id)", "as.factor(season)"),
                  c("as.factor(d_client)", "as.factor(sample_id)", "as.factor(season)", "age", "age2"))


# run this in parallel to speed up the process
# load the data and variables and packages into the cluster
regFileRw <- "regFile_through2017b.RData"
#forceUpdate <- forceUpdateAll

if(!file.exists(regFileRw) || forceUpdate) {
library(parallel)
no_cores <- detectCores() - 1

cl <- makeCluster(no_cores, type="FORK")
clusterEvalQ(cl, "plm")
clusterExport(cl, "rwDat")
clusterExport(cl, "keySoilVars")
clusterExport(cl, "indFeList")

indFeLoopRw <- parLapply(cl, indFeList, function(mod){
  lapply(keySoilVars, function(outcome){
    
    form = lm(reformulate(termlabels = mod, response = outcome), data=rwDat)
    
    pdf(file=paste("output/rw2017b/", paste0(outcome, paste(mod, collapse = "")), ".pdf", sep = "")) 
    print(plot(form))
    dev.off()
    
    form = plm(form, c("sample_id", "age", "age2"))
    
    rownames(form) = paste(rownames(form), outcome, sep = " ")
    return(form)
  })
  
})
stopCluster(cl)
save(indFeLoopRw, file=regFileRw)
} else {
  load(regFileRw)
}

modExportRw <- lapply(indFeLoopRw, function(models){
  do.call(rbind, models)
})

for(i in 1:length(modExportRw)){
  write.csv(modExportRw[i], file=paste0("output/rw2017b/","regOutput_", i, ".csv"), row.names = T)
}

finalModelRw <- modExportRw[4]

kable(finalModelRw, format="markdown")
write.csv(finalModelRw, file="output/rw2017b/indFe_rw2017.csv")
```


# Appendix

Nothing to see here
