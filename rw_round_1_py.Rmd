---
title: "Rwanda Soil Health Study"
author: '[Matt Lowes](mailto:matt.lowes@oneacrefund.org)'
date: '`r format(Sys.time(), "%B %d, %Y")`'
output:
  html_notebook:
    number_sections: yes
    code_folding: show
    theme: flatly
    toc: yes
    toc_depth: 6
    toc_float: yes
subtitle: "Yield Paired Round 1"
---

```{r setup, include=FALSE}
#### set up
## clear environment and console
rm(list = ls())
cat("\014")

## set up some global options
# always set stringsAsFactors = F when loading data
options(stringsAsFactors=FALSE)

# show the code
knitr::opts_chunk$set(echo = TRUE)

# define all knitr tables to be html format
options(knitr.table.format = 'html')

# change code chunk default to not show warnings or messages
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

libs <- c("dplyr", "reshape2", "knitr", "ggplot2", "tibble", "readxl", 
    "MASS", "gridExtra", "cowplot", "robustbase", "car", "RStata", "foreign",
    "tidyr", "readxl")
lapply(libs, require, character.only = T, quietly = T, warn.conflicts = F)

#### define helpful functions
# define function to adjust table widths
html_table_width <- function(kable_output, width) {
  width_html <- paste0(paste0('<col width="', width, '">'), collapse = "\n")
  sub("<table>", paste0("<table>\n", width_html), kable_output)
}

options("RStata.StataVersion" = 12)
options("RStata.StataPath" = "/Applications/Stata/StataSE.app/Contents/MacOS/stata-se")
```

# Objectives

The objectives of this notebook are to analyze the results from the first follow up round of the Rwanda long term soil health study.

# Key Takeaways

> See section with [Notes for Nathaniel](#lessons-for-nathaniel)

> See section with [Notes for Patrick and Step](#soil-notes-for-patrick-and-step)

> [Paired Yield and Soil](#clean-soil-ids) ids are a mess. We lose a lot of observations due to unreconciliable duplicates or ids that simply don't have a match. We lose almost 500 observations.

> See [initial yield response analysis](#individual-soil-models)

TODO - check projection from baseline maps, are they shifted over?
TODO - how to connect photos to farmers for enumerators

# Data Prep

```{r}
dataDir <- normalizePath(file.path("..", "..", "data"))
forceUpdateAll <- FALSE

source("../oaflib/commcareExport.R")
```

How do soil attributes predict yields (climbing beans) >> can we understand yield as functions of carbon, pH, etc. Are the curves as we might expect?

## Load yield data

The variable names from Commcare are in Kinyarwanda and a bit of a mess. I'm going to try to use the names from the Commcare form export. Or is there a way to get this information from Commcare? Surely there must be. 

```{r}
bean <- getFormData("oafrwanda", "M&E", "16B ALL Isarura (Harvest)", forceUpdate = forceUpdateAll)
write.csv(bean, file="rawCcYpData.csv", row.names=F)

yieldNames <- read.table(unz("2016B Harvest2017-06-08.zip", "Forms.csv"), nrows=10, header=T, quote="\"", sep=",") # only first 10 rows

# print variable names together
write.csv(data.frame(names(bean)[1:100], names(yieldNames)[1:100]), file="matchYieldNames.csv")

# get names from cc
# appName <- "M&E"
# formName <- "16B ALL Isarura (Harvest)"
# moduleIdx=NA
appData <- getAppStructure("oafrwanda")

enNames <- getFormFromApp(appData, "M&E", "16B ALL Isarura (Harvest)")$values

# leads to duplicates
onlyVarName <- strsplit(enNames, "/", fixed=F)

newNames <- do.call(rbind, lapply(onlyVarName, function(x){
  return(x[[length(x)]])
}))

names(bean)[11:length(names(bean))] <- newNames #had to change this to 11 on 8/2 due to come CC API update?

#names(bean)[duplicated(names(bean))]

# update intercrop names so that they're unique >> manual cleaning
names(bean)[61:70] <- paste("plants_box1", names(bean)[61:70], sep="_")
names(bean)[82:91] <- paste("plants_box2", names(bean)[82:91], sep="_")

names(bean)[170] <- paste0("climbing_beans_", names(bean)[170])
names(bean)[177] <- paste0("bush_beans_", names(bean)[177])

names(bean)[171] <- paste0("climbing_beans_", names(bean)[171])
names(bean)[178] <- paste0("bush_beans_", names(bean)[178])

names(bean)[173] <- paste0("climbing_beans_", names(bean)[173])
names(bean)[180] <- paste0("bush_beans_", names(bean)[180])

names(bean)[174] <- paste0("climbing_beans_", names(bean)[174])
names(bean)[181] <- paste0("bush_beans_", names(bean)[181])

names(bean)[211] <- paste0("bush_beans", names(bean)[211])
names(bean)[221] <- paste0("maize_", names(bean)[221])

#deal with duplicated variable names
names(bean)[duplicated(names(bean))] <- paste0(names(bean)[duplicated(names(bean))],"_1")
```

The best version of English names don't come from the data labels. They come from another portion of the output. I've extracted it here but a key point of feedback for Nathaniel will be to make certain that going forward variable labels are in the right places.

## Load soil

It's probably safe to assume that if there isn't a soil code the data can be dropped. It's not clear how to match the yield data to the soil data. There might be a way to use the client id from the SHS data but I also don't know if that maps to the M&E data. I could try it if Nathaniel doesn't have a suggestion.

```{r}
#names(bean)[grep("soil",names(bean))]
#names(bean)[grep("id",names(bean))]
#table(bean$soil_code, useNA = 'ifany')
pairedSoilDir <- normalizePath(file.path("..", "..", "OAF Soil Lab Folder", "Projects", "rw_shs_16b_paired_climbing", "4_predicted", "other_summaries"))
pairedSoil <- read.csv(file=paste(pairedSoilDir, "combined-predictions-including-bad-ones.csv", sep = "/"))

pSoilIdDir <- normalizePath(file.path("..", "..", "OAF Soil Lab Folder", "Projects", "rw_shs_16b_paired_climbing", "5_merged"))
pSoilIds <- read.csv(file=paste(pSoilIdDir, "database.csv", sep = "/"))
```

### Clean soil ids

Helpful links: [mutate_each](https://stackoverflow.com/questions/27027347/mutate-each-summarise-each-in-dplyr-how-do-i-select-certain-columns-and-give) and [var names to lower](https://stackoverflow.com/questions/29264028/dplyr-or-magrittr-tolower)

```{r}
psi <- pSoilIds %>% 
  setNames(tolower(names(.))) %>%
  mutate_each(funs(tolower), district, cell) %>%
  rename(ssn = lab.ssn) %>% 
  mutate(
    idDups = duplicated(id) | duplicated(.[nrow(.):1, "id"])[nrow(.):1],
    ssnDups = duplicated(ssn) | duplicated(.[nrow(.):1, "ssn"])[nrow(.):1]
  )

pairedSoil <- pairedSoil %>% 
  setNames(tolower(names(.)))

#table(psi$ssn %in% pairedSoil$ssn) # FALSE  TRUE  41   703 
#table(pairedSoil$ssn %in% psi$ssn) # FALSE  TRUE  27   703 

pairedSoil <- left_join(pairedSoil, psi, by="ssn") # keeps all paired soil values, no duplicated ids
```

And now check how many soil ids are duplicated in the bean data. Is there any hope of untangling which ones are suppoed to be which based on the info provided in the soil data?

```{r}
beanCheck <- bean %>% 
  filter(!is.na(soil_code)) %>%
  mutate(
    idDups = duplicated(soil_code) | duplicated(.[nrow(.):1, "soil_code"])[nrow(.):1]
  )

beanCheck %>% 
  filter(idDups==TRUE) %>%
  arrange(soil_code) %>%
  dplyr::select(district, cell, soil_code)

```

And let's compare this to the ids in the soil data to see if we can find matches. If I can, I'll need to make a new unique id to match them.

```{r}
#vector of duplicated ids in the bean data
idComps <- unique(beanCheck$soil_code[beanCheck$idDups==TRUE])

pairedSoil %>% 
  filter(id %in% idComps) %>%
  arrange(id) %>%
  dplyr::select(district, cell, id)
```

Visually it doesn't seem that there are easy matches to be made. We obviously don't have any -88s or 0s in the id data. 

* `24764` Gitega g doesn't exist. 
* `44337` There are two murambi and we have no further distinguishing info.
* `183004` the name is entirely different.
* `1326301` kibyagira seems to be the best match!
* `9050401` the names are the same.
* `14160102` the names are the same.

Fix the one duplicate we can, drop the others and merge the yield data with the soil data. 
TODO - still waiting on Nathaniel for guidance on how to calculate climbing bean yield. I can take a look at this and see if I can guess.

TODO - follow up with Nathaniel about the soil ids not matching.

```{r}
bean <- bean[-which(bean$soil_code==1326301 & bean$cell=="Gahira"),]
```

```{r}
py <- bean %>% 
  filter(!is.na(soil_code)) %>%
  mutate(
    idDups = duplicated(soil_code) | duplicated(.[nrow(.):1, "soil_code"])[nrow(.):1]
  ) %>% 
  filter(idDups==FALSE) %>%
  rename(ns = id, # change the bean id to something else,  nonsense
         id = soil_code) 
```

We lose `r dim(beanCheck)[1] - dim(py)[1]` obs to duplicated or useless ids.

```{r}
loss <- table(py$id %in% pairedSoil$id)[[1]]
#py$id[!py$id %in% pairedSoil$id]
#table(pairedSoil$id %in% py$id)
```

We then lose `r loss` to not having matches. We're not getting good value for our money here.

```{r}
toJoin <- names(pairedSoil)[c(2:22,25)]

py <- py %>%
  inner_join(., pairedSoil[,toJoin], by="id")

```

## Clean and construct vars

I'm going to take a quick guess at how kg/m2 and t/ha yield calculations were made so that I can set up the analyses I want. I'm first incorporating chagnes to the data Alex Villec did in his .do file. See `cleans_harvest_16b.do` starting on line 85.

```{r}
py$box_length1 <- ifelse(py$d_box_lenght1!=7 & py$d_box_lenght1!=3, 5, py$d_box_lenght1)
py$box_width1 <- ifelse(py$d_box_width1!=7 & py$d_box_width1!=3, 5, py$d_box_width1)

py$box_length2 <- ifelse(py$d_box_length2!=7 & py$d_box_length2!=3, 5, py$d_box_length2)
py$box_width2 <- ifelse(py$d_box_width2!=7 & py$d_box_width2!=3, 5, py$d_box_width2)

```

```{r}
calculateYield <- function(bagA, bagB, lenA, lenB, widthA, widthB, df) {
  
  #convert to numeric
  df[,c(bagA, bagB, lenA, lenB, widthA, widthB)] <- sapply(df[,c(bagA, bagB, lenA, lenB, widthA, widthB)], function(x){
    as.numeric(as.character(x))
  })
  
  # calculate box areas
  df$boxAreaA <- df[,lenA] * df[,widthA]
  df$boxAreaB <- df[,lenB] * df[,widthB]

  df$yieldA <- df[,bagA] / df$boxAreaA
  df$yieldB <- df[,bagB] / df$boxAreaB

  df$yieldProbsA <- is.na(df$yieldA) | is.infinite(df$yieldA)
  df$yieldProbsB <- is.na(df$yieldB) | is.infinite(df$yieldB)

  df$yield <- (df[,bagA] + df[,bagB]) / (df$boxAreaA + df$boxAreaB)
  
  df$yield[!df$yieldProbsA & df$yieldProbsB] <- 
    df$yieldA[!df$yieldProbsA & df$yieldProbsB]
  df$yield[!df$yieldProbsB & df$yieldProbsA] <- 
    df$yieldB[!df$yieldProbsB & df$yieldProbsA]
  return(df)
}

py <- calculateYield("box_kg1", "box_kg2", "box_length1", "box_length2", "box_width1", "box_width2", py)

respVar <- c(names(py)[which(names(py)=="ph"): which(names(py)=="x.total.nitrogen")], "yield")

#yr <- py[,names(py) %in% respVar]
py$tha <- py$yield * 10

soilVars <- names(py)[which(names(py)=="ph"):which(names(py)=="x.total.nitrogen")]
keySoilVars <- c("ph", "x.organic.carbon", "x.total.nitrogen", "calcium", "magnesium")
```

```{r}
iqr.check <- function(dat, x) { 
  q1 = summary(dat[,x])[[2]]
  q3 = summary(dat[,x])[[5]] 
  iqr = q3-q1
  mark  = ifelse(dat[,x] < (q1 - (1.5*iqr)) | dat[,x] > (q3 + (1.5*iqr)), 1,0)
  tab = rbind(
    summary(dat[,x]),
    summary(dat[mark==0, x])
  )
  return(tab)
}


soilYTab <- do.call(plyr::rbind.fill, lapply(soilVars, function(y){
  #print(y)
  res = iqr.check(py, y)
  #print(dim(res))
  out = data.frame(var=rbind(y, paste(y, ".iqr", sep="")), res)
  return(out)
}))

soilYTab[,2:length(soilYTab)] <- sapply(soilYTab[,2:length(soilYTab)], function(x){round(x,2)})
```

The outlier table summarizes the numeric variables with and without IQR outliers to show how the data changes based on this filter.

```{r}
knitr::kable(soilYTab, row.names = F, digits = 3, format = 'markdown')
```

Impose sensible constraints on soil variables

**Ask Patrick and Step what those might be**. The table above removes IQR outliers. The check below removes based on 3sd so the values are different.

```{r}
check.3sd <- function(x) {
  x = ifelse(is.infinite(x), NA, x)
  mean = mean(x, na.rm=T)
  sd = sd(x, na.rm=T)
  mark = ifelse(x>(mean + (3*sd)) |
        x<(mean - (3*sd)), NA, x)
  return(mark)
}


sdSoilVals.py <- py %>%
  dplyr::select(one_of(soilVars)) 

sdCheck.py <- as.data.frame(apply(sdSoilVals.py, 2, function(x){
  return(check.3sd(x))
}))

names(py)[which(names(py)=="ph"):which(names(py)=="x.total.nitrogen")] <- paste0(names(py)[which(names(py)=="ph"):which(names(py)=="x.total.nitrogen")], ".raw")

py <- cbind(py, sdCheck.py)
```

# Point of diminishing returns

The best option would be to identify it visually. However, we are not seeing a clear point of diminishing returns visually suggesting that our data doesn't support this hypothesis of a point of diminishing returns despite there being an accepted theoretical point.

## Pure one to one

Graphs to show the relationship between soil parameter and yield. We don't expect this relationships to be linear. A couple notes:

* None seems to show any clear increasing or decreasing value across the spectrum of yield values.
* Nitrogen has a bimodal appearance with the second hump at 0.25. Why do we not have support for the values between 0.2 and 0.25?
* Magnesium seems to have a long right tail still. 

**The goal is to identify the point of diminishing returns for the simplistic soil parameter yield model** 

The actual relationship is likely more complex but defining that model is outside the scope of this research. If we were to include other parameters in the model, we'd have to run simluations to determine the global minimum for ph based all values of calcium, magnesium, and whatever else we add in the model. If we had multiple additional coefficients, it gets hugely complicated.

```{r}
for(i in 1:length(keySoilVars)){
  print(
  ggplot(py, aes(x = py[,keySoilVars[i]], y = tha)) + 
    geom_point() +
    stat_smooth() +
    geom_vline(xintercept=summary(py[,keySoilVars[i]])[[2]], linetype="dashed") + 
    geom_vline(xintercept=summary(py[,keySoilVars[i]])[[5]], linetype="dashed") + 
    labs(title = keySoilVars[i], x= keySoilVars[i], y="Yield (t/ha)")
  )
}
```

* For each soil parameter, first write out the theoretical model, for instance quadradic relationship between ph and yield
* solve for where ph2 cancels out ph coefficient
* timing is not great as these are taken at harvest as opposed 
* Try aggregating to a higher geographic level, average ph on average yield

## Log response

```{r}
for(i in 1:length(keySoilVars)){
  print(
  ggplot(py, aes(x = py[,keySoilVars[i]], y = log10(tha))) + 
    geom_point() +
    stat_smooth() +
    #geom_vline(xintercept=summary(py[,keySoilVars[i]])[[2]], linetype="dashed") + 
    #geom_vline(xintercept=summary(py[,keySoilVars[i]])[[5]], linetype="dashed") + 
    labs(title = keySoilVars[i], x= keySoilVars[i], y="Yield (t/ha)")
  )
}
```

## Cell level model

```{r}
py$cell <- tolower(py$cell)

aggCell <- py %>%
  group_by(cell) %>%
  summarize_each(funs(mean(., na.rm=T)), c(tha, ph, x.organic.carbon, x.total.nitrogen, calcium, magnesium)) %>%
  as.data.frame()
```

```{r}
for(i in 1:length(keySoilVars)){
  print(
  ggplot(aggCell, aes(x = aggCell[,keySoilVars[i]], y = tha)) + 
    geom_point() +
    stat_smooth() +
    #stat_smooth(method="lm", color="red")+
    labs(title = keySoilVars[i], x= keySoilVars[i], y="Yield (t/ha)")
  )
}
```

The cell level results seem a bit more useable (??? big question mark). I'll try to fit the expected relationship to these data and see where the coefficients cancel each other out

```{r}
aggCell$ph2 <- aggCell$ph^2

theoryPh <- lm(tha ~ ph + ph2, data=aggCell)

```

* For this to work we need ph2 to be negative and ph to be positive so that low ph values so that at low ph values the ph term dominates the quadratic term. 
* as ph increases, the quadratic term becomes more important
* other papers estimate quadratic funciton and see where they cancel out

### Carbon quadratic

```{r}
aggCell$c2 <- aggCell$x.organic.carbon^2
theoryC <- lm(tha ~ x.organic.carbon + c2, data=aggCell)
summary(theoryC)

beta1 <- summary(theoryC)$coeff[2]
beta2 <- summary(theoryC)$coeff[3]

keyPoint <- (-beta1)/(2*beta2)

ggplot(aggCell, aes(x = x.organic.carbon, y = tha)) + 
    geom_point() +
    #stat_smooth() +
    stat_function(fun=function(x) log(x)) + 
    geom_vline(xintercept=keyPoint) + 
    #stat_smooth(method="lm", color="red")+
    labs(title = "Carbon", x = "Carbon", y="Yield (t/ha)")
```

### Carbon logrithmic

Scrap as there isn't a clear way to fit a linear model and get diminishing returns without a quadratic ceofficient. The logrithimic never actually reaches zero so there isn't a true point at which it decreases to zero.

```{r}
theoryCLog <- lm(log10(tha) ~ x.organic.carbon, data=subset(aggCell, aggCell$tha>1))
summary(theoryCLog)

beta1 <- summary(theoryC)$coeff[2]
#beta2 <- summary(theoryC)$coeff[3]

keyPoint <- (-beta1)/(2*beta2)

ggplot(aggCell, aes(x = x.organic.carbon, y = tha)) + 
    geom_point() +
    #stat_smooth() +
    stat_function(fun=function(x) log(x)) + 
    geom_vline(xintercept=keyPoint) + 
    #stat_smooth(method="lm", color="red")+
    labs(title = "Carbon", x = "Carbon", y="Yield (t/ha)")
```

This analysis concludes that the point of diminishing returns for carbon is at `r round(keyPoint,2)`. 

### Generalized formulas (test)

You can kind of estimate log with quadratic assuming that the squared term is negative

```{r}
ggplot(data.frame(x = c(-4, 4)), aes(x = x)) +
        stat_function(fun = function(x) x - x^2)
```

```{r}
ggplot(data.frame(x = c(-4, 4)), aes(x = x)) +
        stat_function(fun = function(x) log(x))
```

### Wet chem only

Try looking at these relationships with only wet chemistry data to minimize prediction noise. Start with the simple scatter plot and then progress to quadratic formula if 

```{r}
pairedWetDir <- normalizePath(file.path("..", "..", "OAF Soil Lab Folder", "Projects", "rw_shs_16b_paired_climbing", "3_wet_chem"))
pairedWet <- read.csv(file=paste(pairedWetDir, "wet_chem.csv", sep = "/"))

pSoilIdDir <- normalizePath(file.path("..", "..", "OAF Soil Lab Folder", "Projects", "rw_shs_16b_paired_climbing", "5_merged"))
pSoilIds <- read.csv(file=paste(pSoilIdDir, "database.csv", sep = "/"))


pairedWet <- pairedWet %>%
  mutate(
    Field.Name = tolower(Field.Name)
  ) %>%
  rename(
    LAB.SSN = Field.Name
  ) %>%
  filter(LAB.SSN!="") %>%
  left_join(., pSoilIds, by="LAB.SSN") %>% 
  rename(
    ssn = LAB.SSN
  ) %>%
  left_join(., py[,c("tha", "ssn")], by="ssn")

names(pairedWet) <- tolower(names(pairedWet))
```

Check out what is not merging. Visually we just don't seem to have full matches. I don't understand how that's possible though given that we used these wet chem values to predict the soil values.

```{r}
# pairedWet$ssn[is.na(pairedWet$tha)]
# 
# pairedWet$ssn[!pairedWet$ssn %in% py$ssn]
# sort(py$ssn[!py$ssn %in% pairedWet$ssn])

#py$ssn[grep("35", py$ssn)]
```
```{r}
for(i in 1:length(keySoilVars)){
  print(
  ggplot(pairedWet, aes(x = pairedWet[,keySoilVars[i]], y = tha)) + 
    geom_point() +
    stat_smooth() +
    #stat_smooth(method="lm", color="red")+
    labs(title = keySoilVars[i], x= keySoilVars[i], y="Yield (t/ha)")
  )
}
```

Quick overview:

* pH again doesn't make much sense
* Carbon looks alright. Let's take a closer look
* Nitrogen looks useable as well.
* Calcium looks really odd
* Magnesium looks like calcium; really odd.

```{r}
pairedWet$c2 <- pairedWet$x.organic.carbon^2
theoryWC <- lm(tha ~ x.organic.carbon + c2, data=pairedWet)
#summary(theoryWC)

beta1 <- summary(theoryWC)$coeff[2]
beta2 <- summary(theoryWC)$coeff[3]

keyPoint <- (-beta1)/(2*beta2)

ggplot(pairedWet, aes(x = x.organic.carbon, y = tha)) + 
    geom_point() +
    #stat_smooth() +
    stat_function(fun=function(x) log(x)) + 
    geom_vline(xintercept=keyPoint) + 
    #stat_smooth(method="lm", color="red")+
    labs(title = "Carbon", x = "Carbon", y="Yield (t/ha)")
```
This analysis concludes that the point of diminishing returns for carbon is at `r round(keyPoint,2)`. 

### PDP

Try looking at partial dependence plots to have a clear functional form to eyeball a tipping point in changes in pH on yield. This would likely be pretty difficult because pH may not be important in the ranked importance plots and it might not a functional form that fits with what we expect. 


# Soil quartile

```{r}
yQuartiles <- function(yVar, xVar, df){
  applyCuts = cut(df[,xVar], breaks=quantile(df[,xVar],c(0.25, 0.5, 0.75, 1),type=1, na.rm=T))
  tab = tapply(df[,yVar], applyCuts, mean)
  #diff = tab[[4]] - tab[[1]]
  return(tab)
}

yQChange <- function(tab, start, end){ #start and end are the indicies
  diff = tab[[end]]-tab[[start]]
  return(diff)
}

qTab <- do.call(rbind, lapply(keySoilVars, function(x){
  yQuartiles("tha", x, py)
}))
qTab <- as.data.frame(qTab)
names(qTab) <- c("q25to50","q50to75","q75to100")

qTab <- as.data.frame(sapply(qTab, function(x){round(x,2)}))

qTab <- cbind(qTab, 
              diff25to50 = apply(qTab, 1, function(x){
                  yQChange(x,1,2)}),
              diff50to75 = apply(qTab, 1, function(x){
                  yQChange(x,2,3)}))
```

Add in revenue calculation. Assume that farmers are earning 25c a kg so $250/ton and we're moving the bottom quarter of our sample to the 75th percentile.

```{r}
library(scales)
# add revenue
marketValueT <- 250
numFarmersRw <- 164500/4
qTab$revenueA <- dollar(qTab$diff25to50 * marketValueT)
qTab$revenueB <- dollar(qTab$diff50to75 * marketValueT)

write.csv(qTab, file="output/quartileCalc.csv")
```

## Minimum Threshold

Programmatic value of moving 75% of farmers above minimum soil threshold. A couple notes:

```{r}
minThresh <- function(xVar, yVar, per.thold, thold, FarmerCount, marketValue, df){
  # figure out where the threshold is in terms of percentile of xVar
  # calculate value of moving farmers below that percentile above that perentile in terms of yield gain
  
  dist <- ecdf(df[,xVar])
  perce <- dist(thold)
  
  # amount above thold
  inClear <- 1-perce
  remainToMove <- ifelse(per.thold-inClear>0, per.thold - inClear, 0)
  remainToMoveFarmers <- FarmerCount*remainToMove
  
  startingPointX <- quantile(df[,xVar], c(perce - remainToMove), type=1, na.rm = T)[[1]]
  
  # yield value above threshold
  above <- mean(df[,yVar][df[,xVar]>thold], na.rm = T) #this is the average for all above threshold
  
  #distance between farmers yield value and threshold yield value for farmers below threshold and within the percentile we want to move up.
  
  remaining <-subset(df, df[,xVar]>=startingPointX & df[,xVar]<=thold)
  bump <- above - remaining[,yVar]
  
  marketValuetha <- marketValue*1000
  
  #average value add
  res <-mean(bump, na.rm = T) * remainToMoveFarmers * marketValuetha
  res <- paste(format(round(res / 1e6, 2), trim = TRUE), "M")  
  
  
  return(res)
}

progImpactpH <- minThresh("ph", "tha", 0.75, 5.8, 282228, 0.52, py)
progImpactN <- minThresh("x.total.nitrogen", "tha", 0.75, 0.1, 282228, 0.52, py)
progImpactC <- minThresh("x.organic.carbon", "tha", 0.75, 2, 282228, 0.52, py)
progImpactCa <- minThresh("calcium", "tha", 0.75, 1056, 282228, 0.52, py)
progImpactMg <- minThresh("magnesium", "tha", 0.75, 148, 282228, 0.52, py)

progObj <- ls()[grep("progImpact", ls())]
  
progImpTab <- do.call(rbind, lapply(progObj, function(x){get(x)}))
progImpTab <- data.frame(var = progObj, value = progImpTab)

write.csv(progImpTab, file=paste("output/", "rwandaThresholdTab.csv", sep=""), row.names = F)
```

